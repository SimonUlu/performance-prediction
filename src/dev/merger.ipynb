{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten einlesen und vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bereinige_und_speichere_csv(input_csv):\n",
    "    # Lese das CSV ein\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Finde alle Spalten, die 'loadgenerator.2' enthalten\n",
    "    spalten_zu_entfernen = [spalte for spalte in df.columns if 'pod-14' in spalte]\n",
    "    \n",
    "    # Entferne diese Spalten aus dem DataFrame\n",
    "    df_bereinigt = df.drop(spalten_zu_entfernen, axis=1)\n",
    "    \n",
    "    # Speichere das bereinigte DataFrame am urspr√ºnglichen Speicherort\n",
    "    df_bereinigt.to_csv(input_csv, index=False)\n",
    "\n",
    "# Ersetze \"dein_csv_pfad.csv\" mit dem Pfad zu deinem CSV\n",
    "bereinige_und_speichere_csv(\"./../../timeseries/merged/constant-load/medium/file.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alle Files zusammen mergen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./../../timeseries/preprocessed-final/tea-store/three/file.csv', './../../timeseries/preprocessed-final/tea-store/one/file.csv', './../../timeseries/preprocessed-final/tea-store/two/file.csv', './../../timeseries/preprocessed-final/peak-load/slower/file.csv', './../../timeseries/preprocessed-final/peak-load/faster/file.csv', './../../timeseries/preprocessed-final/newer/medium/file.csv', './../../timeseries/preprocessed-final/newer/long/file.csv', './../../timeseries/preprocessed-final/constant-load/high_low/file.csv', './../../timeseries/preprocessed-final/constant-load/medium/file.csv', './../../timeseries/preprocessed-final/constant-load/long/file.csv', './../../timeseries/preprocessed-final/long-time/high/file.csv', './../../timeseries/preprocessed-final/long-time/low/file.csv', './../../timeseries/preprocessed-final/service-penetration/checkout/file.csv', './../../timeseries/preprocessed-final/service-penetration/cart/file.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"./../../timeseries/preprocessed-final\"\n",
    "all_files = glob.glob(path + '/**/*.csv', recursive=True)\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header= 0)\n",
    "    df_list.append(df)\n",
    "\n",
    "combined_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('./../../timeseries/preprocessed-final/combined_timeseries.csv', index=False)\n",
    "\n",
    "# combined_df.head(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
