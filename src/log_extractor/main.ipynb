{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and set filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../locust_logs/meine_logs.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "filepath = \"./../../locust_logs/\"\n",
    "\n",
    "filename = \"meine_logs.txt\"\n",
    "\n",
    "log_file_path = filepath + filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare empty arrays and helper vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "requests = []\n",
    "failures = []\n",
    "avg_response_times = []\n",
    "current_users = []\n",
    "current_users_count = 0\n",
    "time_spent_in_seconds = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data from .txt file to timeseries arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (log_file_path, \"r\") as file:\n",
    "\n",
    "    current_users.append(current_users_count)\n",
    "    timestamps.append(time_spent_in_seconds)\n",
    "\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Aggregated\"):\n",
    "            \n",
    "            ## increment users and time\n",
    "            time_spent_in_seconds += 2\n",
    "            current_users_count += 2\n",
    "            \n",
    "            ## Preprocess data \n",
    "            line = line.replace(\"|\", \"\")\n",
    "            line = re.sub(r'\\s+', '|', line)\n",
    "            line = line.replace(\" \", \"\")\n",
    "            data = line.split(\"|\")\n",
    "            \n",
    "            ## add data to timeseries arrays\n",
    "            timestamps.append(time_spent_in_seconds)\n",
    "            requests.append(data[1])\n",
    "            failures.append(data[2])\n",
    "            avg_response_times.append(data[3])\n",
    "            current_users.append(current_users_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate avg response time in interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [int(r) for r in requests] \n",
    "avg_response_times = [int(t) for t in avg_response_times]\n",
    "requests_diff = [j-i for i, j in zip(requests[:-1], requests[1:])]\n",
    "avg_response_time_intervals = []\n",
    "\n",
    "for i in range(1, len(requests)): \n",
    "    # Gesamtantwortzeit bis zum aktuellen Zeitpunkt \n",
    "    total_response_time_current = avg_response_times[i] * requests[i]\n",
    "    # Gesamtantwortzeit bis zum vorherigen Zeitpunkt\n",
    "    total_response_time_previous = avg_response_times[i-1] * requests[i-1]\n",
    "\n",
    "    # Gesamtantwortzeit im aktuellen Intervall\n",
    "    total_response_time_interval = total_response_time_current - total_response_time_previous\n",
    "\n",
    "    # Anzahl der Anfragen im aktuellen Intervall\n",
    "    requests_interval = requests_diff[i-1]\n",
    "\n",
    "    if requests_interval > 0:\n",
    "        # Durchschnittliche Antwortzeit im Intervall\n",
    "        avg_response_time_interval = total_response_time_interval / requests_interval\n",
    "        if (avg_response_time_interval < 0):\n",
    "            avg_response_time_interval = 0\n",
    "    else:\n",
    "        avg_response_time_interval = 0\n",
    "\n",
    "    avg_response_time_intervals.append(avg_response_time_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 46.0, 23.5, 58.0, 36.75, 17.75, 29.6, 40.5, 4.0, 22.666666666666668, 70.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64]\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 31, 40, 39, 34, 33, 35, 34, 33, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 9, 13, 17, 22, 30, 31, 34, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]\n"
     ]
    }
   ],
   "source": [
    "print(avg_response_time_intervals) ## prints the avg response times in miliseconds\n",
    "print(current_users)\n",
    "print(timestamps)\n",
    "print(avg_response_times)\n",
    "print(requests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
